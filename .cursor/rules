# ResumeForge — Cursor Project Rules (v2)

These rules are the **single source of truth** for how Cursor should generate code in this repo.

## Non‑negotiables

1. **Evidence-first truthfulness**
   - No resume claim may appear in any output unless it is traceable to one or more `EvidenceCard.id` values.
   - Every bullet must carry `evidence_ids: list[str]` internally (even if hidden from the final DOCX).
   - If the auditor detects an ungrounded claim, the run **fails** (no “best effort” guessing).

2. **Config is the source of truth**
   - Do not hardcode provider model IDs or API behavior in code.
   - Load configuration only via `resumeforge/config.py` (or equivalent).
   - If you need a new setting, add it to `config.yaml` and the Pydantic config schema.

3. **No direct SDK calls outside Providers**
   - Agents must never call OpenAI/Anthropic/Google/Groq SDKs directly.
   - Agents call a `ProviderClient` interface (e.g., `generate(...)`) implemented in `resumeforge/providers/*`.

4. **Typed, validated boundaries**
   - All structured data crossing module boundaries must be a Pydantic v2 model.
   - Every provider response intended as structured data must be parsed/validated into a Pydantic model.

5. **Testability**
   - Every agent must be unit-testable with a fake provider (no network).
   - Orchestrator must have a “golden path” test using fixtures.

## Project layout and imports

**Always use package imports** (never `src.` imports):

- ✅ `from resumeforge.schemas.blackboard import Blackboard`
- ❌ `from src.schemas.blackboard import Blackboard`

Recommended layout:

```
resumeforge/
  src/
    resumeforge/
      cli.py
      config.py
      orchestrator/
      agents/
      providers/
      schemas/
      parsers/
      generators/
      utils/
  tests/
  config.yaml
  pyproject.toml
```

## Coding standards

- Keep modules cohesive; split files when a file grows past ~300 lines or mixes responsibilities.
- Prefer pure functions and small classes; avoid “god objects”.
- Logging must be structured (`structlog`) and include: `run_id`, `job_id`, `agent`, `provider`, `model`, `attempt`.
- Handle errors explicitly using typed exceptions (see Error policy below).

### Error policy

Define and use a small set of exceptions:

- `ConfigError` — invalid/missing config
- `ValidationError` — Pydantic validation failures (wrap/extend if needed)
- `ProviderError` — provider/network/SDK failures
- `OrchestrationError` — pipeline coordination failures

Rules:
- Provider layer converts SDK exceptions → `ProviderError` with context.
- Orchestrator decides retry/fallback behavior based on config.
- Agents never swallow errors silently; they return typed results or raise.

## Configuration rules

- `config.yaml` is an example. Local overrides should use `config.local.yaml` (gitignored).
- Model selection uses **aliases**:
  - Agents reference `model_alias` (e.g., `writer_default`), not raw model IDs.
  - Provider resolves alias → provider-specific model string from config.

## Provider interface

All providers implement a consistent interface:

- `generate_text(prompt: str, *, model: str, temperature: float, max_tokens: int, ...) -> str`
- Optional: `generate_json(schema: type[BaseModel], ...) -> BaseModel` (recommended helper)

Providers must:
- apply timeouts/retries (prefer `tenacity`)
- support deterministic mode for auditors (`temperature=0.0`)
- emit structured logs per attempt

## Agent contracts

Each agent must declare:
- Inputs: required blackboard keys
- Outputs: produced keys
- Side effects: none (except writing to blackboard)

Common agents (per ADR-004, SDD Section 4):
- `JD Analyst + Strategy` → analyzes job description, determines positioning
- `EvidenceMapper` → selects relevant evidence cards, maps to requirements
- `Writer` → creates bullets + sections (internal claim index)
- `ATS Scorer` → scores keyword coverage, format compatibility
- `TruthAuditor` → validates claims against evidence, enforces policy
- `DOCXGenerator` → renders output document from audited content (not an agent, but generator)

## Claim index (required)

Writer must produce `claim_index.json` with:

- `bullet_id`
- `claim_text`
- `evidence_ids[]`
- `metrics[]` (normalized)
- `timeframe` (if present)
- `confidence` (0–1)
- `risk_flags[]` (e.g., `["timeframe_inferred", "metric_rounded"]`)

Auditor must verify:
- `evidence_ids` not empty
- every metric/timeframe appears in evidence or is flagged as inferred
- no PII leakage beyond allowed fields

## Cursor guidance (how to generate code)

When adding new functionality, generate in this order:
1. Add/extend Pydantic schema(s) in `schemas/`
2. Add provider interface methods (if needed) in `providers/`
3. Add agent implementation in `agents/` with explicit contract
4. Add orchestrator wiring
5. Add unit tests + a golden test fixture

Do not generate multiple competing implementations. Prefer the simplest design consistent with these rules.

## Error Handling Consistency

**CRITICAL**: All validation and input errors must use custom exceptions, not built-in Python exceptions.

### Exception Usage Rules

1. **Validation Errors**: Always use `ValidationError` from `resumeforge.exceptions`
   - ✅ `raise ValidationError("Agent Name: field is required. Please provide...")`
   - ❌ `raise ValueError("field is required")`
   - ❌ `raise FileNotFoundError("file not found")`

2. **Error Message Format**: All ValidationError messages must follow this pattern:
   ```
   "{Component Name}: {issue description}. {Suggested fix or next step}."
   ```
   Examples:
   - ✅ `"JD Analyst: job_description is empty. Please provide a valid job description in blackboard.inputs.job_description"`
   - ✅ `"Evidence Mapper: role_profile is required. Please run JD Analyst agent first to populate role_profile."`
   - ✅ `"Fact Resume Parser: Fact resume file not found: {path}"`
   - ❌ `"job_description is empty"`
   - ❌ `"role_profile required"`

3. **Provider Errors**: Always wrap SDK exceptions in `ProviderError` with context:
   - ✅ `raise ProviderError(f"OpenAI rate limit exceeded: {e}") from e`
   - ❌ `raise RateLimitError(e)`

4. **File Operations**: Use `ValidationError` for file-related validation errors:
   - ✅ `raise ValidationError(f"Fact resume file not found: {resume_path}")`
   - ❌ `raise FileNotFoundError(f"Fact resume file not found: {resume_path}")`

## Constants and Magic Numbers

**CRITICAL**: Extract all magic numbers to named constants at module level.

### Rules:
1. **No magic numbers in code**: Extract to constants with descriptive names
   - ✅ `DEFAULT_TEMPERATURE = 0.3` then use `config.get("temperature", DEFAULT_TEMPERATURE)`
   - ❌ `config.get("temperature", 0.3)`

2. **Constants naming convention**:
   - Use `UPPER_SNAKE_CASE`
   - Prefix with module/component name if module-specific
   - Examples:
     - `DEFAULT_TEMPERATURE = 0.3`
     - `ATS_SCORING_TEMPERATURE = 0.2`
     - `MAX_RESPONSE_PREVIEW_LENGTH = 500`
     - `MARKDOWN_JSON_PREFIX_LENGTH = 7`

3. **Common constants to extract**:
   - Retry counts: `DEFAULT_MAX_RETRIES = 2`, `OPENAI_MAX_RETRIES = 3`
   - Timeouts: `DEFAULT_TIMEOUT_SECONDS = 45`
   - Token limits: `DEFAULT_MAX_TOKENS = 4096`, `ATS_SCORING_MAX_TOKENS = 2048`
   - String lengths: `MAX_RESPONSE_PREVIEW_LENGTH = 500`
   - Numeric divisors: `TOKENS_PER_MILLION = 1_000_000`

## Type Hints Requirements

1. **All function parameters and return types must be annotated**
   - ✅ `def parse(self, resume_path: Path) -> list[EvidenceCard]:`
   - ❌ `def parse(self, resume_path):`

2. **Use TYPE_CHECKING for forward references**:
   ```python
   from typing import TYPE_CHECKING
   
   if TYPE_CHECKING:
       from resumeforge.providers.base import BaseProvider
   ```

3. **Prefer specific types over generic dict**:
   - ✅ `config: Config` (when Config model exists)
   - ⚠️ `config: dict` (acceptable if Config model not available)

## Testing Requirements

1. **Unit tests must use mocked providers** (no real API calls)
   - Use `tests.fixtures.create_mock_provider()` helper
   - All agent unit tests must pass without API keys

2. **Integration tests must be marked**:
   ```python
   @pytest.mark.integration
   @pytest.mark.skipif(not os.getenv("API_KEY"), reason="Requires API_KEY")
   ```

3. **Test coverage target**: Minimum 80% for agents module, 70% overall

4. **Test naming**: `test_{component}_{behavior}_{expected_result}`
   - ✅ `test_jd_analyst_parse_response_valid`
   - ✅ `test_evidence_mapper_invalid_card_ids_filtered`
   - ❌ `test_parse` or `test_analyst`

## Code Quality Checklist

Before committing code, verify:
- [ ] All error messages follow the format: `"{Component}: {issue}. {fix}."`
- [ ] No magic numbers (all extracted to constants)
- [ ] All functions have type hints
- [ ] Custom exceptions used (not ValueError, FileNotFoundError for validation)
- [ ] Unit tests added for new functionality
- [ ] Integration tests marked with `@pytest.mark.integration`
- [ ] Structured logging used (`self.logger.info(...)`)
- [ ] No `print()` statements
- [ ] No wildcard imports (`from module import *`)